{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Walks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"9606.hn_HS_CX.edge\", sep=\"\\t\", header=None)\n",
    "data.drop([3, 4, 5], axis=1, inplace=True)\n",
    "data.columns = [\"node1\", \"node2\", \"weight\"]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nodes = np.array(\n",
    "    list(set(data[\"node1\"].unique()).union(set(data[\"node2\"].unique())))\n",
    ")\n",
    "print(\"Total number of nodes: {}\".format(len(all_nodes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Adjacency Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_symmetric_adjacency_matrix(df):\n",
    "    \"\"\"\n",
    "    Create a symmetric adjacency matrix from a dataframe containing edges and weights.\n",
    "    \"\"\"\n",
    "    df_symmetric = pd.concat(\n",
    "        [df, df.rename(columns={\"node1\": \"node2\", \"node2\": \"node1\"})]\n",
    "    )\n",
    "    df_symmetric = df_symmetric.groupby([\"node1\", \"node2\"]).weight.mean().reset_index()\n",
    "\n",
    "    adjacency_matrix = df_symmetric.pivot(\n",
    "        index=\"node1\", columns=\"node2\", values=\"weight\"\n",
    "    ).fillna(0)\n",
    "\n",
    "    matrix_np = adjacency_matrix.to_numpy()\n",
    "    symmetrized_matrix_np = matrix_np + matrix_np.T - np.diag(matrix_np.diagonal())\n",
    "\n",
    "    return symmetrized_matrix_np\n",
    "\n",
    "\n",
    "def remove_self_loops_and_small_components(adj_matrix, threshold_components=4):\n",
    "    \"\"\"\n",
    "    Remove self-loops and small disconnected components from the graph represented by the adjacency matrix.\n",
    "    Also, keep track of the removed nodes.\n",
    "    \"\"\"\n",
    "    G = nx.from_numpy_array(adj_matrix)\n",
    "    removed_nodes = []\n",
    "\n",
    "    for edge in nx.selfloop_edges(G):\n",
    "        G.remove_edge(*edge)\n",
    "\n",
    "    components = list(nx.connected_components(G))\n",
    "    for component in components:\n",
    "        if len(component) < threshold_components:\n",
    "            removed_nodes.extend(component)\n",
    "            for node in component:\n",
    "                G.remove_node(node)\n",
    "\n",
    "    cleaned_adj_matrix = nx.to_numpy_array(G)\n",
    "\n",
    "    return cleaned_adj_matrix, set(removed_nodes)\n",
    "\n",
    "\n",
    "def normalize_to_stochastic_matrix(adj_matrix):\n",
    "    \"\"\"\n",
    "    Normalize an adjacency matrix so that each row sums to 1, creating a stochastic matrix.\n",
    "    \"\"\"\n",
    "    matrix_np = np.array(adj_matrix)\n",
    "\n",
    "    row_sums = matrix_np.sum(axis=1, keepdims=True)\n",
    "\n",
    "    row_sums[row_sums == 0] = 1\n",
    "\n",
    "    stochastic_matrix = matrix_np / row_sums\n",
    "\n",
    "    return stochastic_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_mat = create_symmetric_adjacency_matrix(data)\n",
    "cleaned_adj_mat, removed_nodes = remove_self_loops_and_small_components(adj_mat)\n",
    "\n",
    "removed_nodes = list(removed_nodes)\n",
    "all_nodes_cleaned = np.delete(all_nodes, removed_nodes)\n",
    "avg_degree = np.count_nonzero(cleaned_adj_mat, axis=1).mean()\n",
    "\n",
    "print(f\"Number of removed nodes: {len(removed_nodes)}\")\n",
    "print(f\"Number of nodes after cleaning: {len(all_nodes_cleaned)}\")\n",
    "print(f\"Average degree: {avg_degree:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stochastic_matrix = normalize_to_stochastic_matrix(cleaned_adj_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Walk Without Restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_walk_without_restart_to_stationary_distribution(\n",
    "    stochastic_matrix, start_node, threshold=1e-4, max_iterations=1000\n",
    "):\n",
    "    \"\"\"\n",
    "    Perform a random walk on a graph represented by a stochastic matrix, starting from a given node,\n",
    "    until the stationary distribution is reached or the maximum number of iterations is exceeded.\n",
    "\n",
    "    :param stochastic_matrix: The stochastic matrix representing the graph.\n",
    "    :param start_node: The index of the starting node.\n",
    "    :param threshold: The threshold for the difference between successive distribution vectors.\n",
    "    :param max_iterations: The maximum number of iterations to perform.\n",
    "    :return: The stationary distribution vector of the random walk.\n",
    "    \"\"\"\n",
    "    num_nodes = stochastic_matrix.shape[0]\n",
    "\n",
    "    q_k = np.zeros(num_nodes)\n",
    "    q_k[start_node] = 1\n",
    "\n",
    "    for _ in range(max_iterations):\n",
    "        q_k_next = np.dot(q_k, stochastic_matrix)\n",
    "\n",
    "        if np.linalg.norm(q_k_next - q_k) < threshold:\n",
    "            break\n",
    "\n",
    "        q_k = q_k_next\n",
    "\n",
    "    return q_k_next\n",
    "\n",
    "\n",
    "def visualize_distributions_heatmap(\n",
    "    *distributions, node_labels=None, distribution_labels=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualize multiple stationary distributions as a heatmap.\n",
    "\n",
    "    :param distributions: Stationary distributions obtained from random walks.\n",
    "    :param node_labels: Labels for the nodes (optional).\n",
    "    :param distribution_labels: Labels for the distributions (optional).\n",
    "    \"\"\"\n",
    "    data = np.vstack(distributions)\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    ax = sns.heatmap(\n",
    "        data,\n",
    "        annot=False,\n",
    "        cmap=\"viridis\",\n",
    "        yticklabels=distribution_labels\n",
    "        if distribution_labels\n",
    "        else [f\"Dist {i + 1}\" for i in range(len(distributions))],\n",
    "        xticklabels=node_labels if node_labels else [],\n",
    "    )\n",
    "    ax.set_title(\"Comparison of Stationary Distributions from Random Walks\")\n",
    "    ax.set_xlabel(\"Nodes\")\n",
    "    ax.set_ylabel(\"Distributions\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationary_distributions = []\n",
    "for i in range(3):\n",
    "    start_node = np.random.randint(stochastic_matrix.shape[0])\n",
    "    print(f\"Starting node: {start_node}\")\n",
    "    stationary_distribution = random_walk_without_restart_to_stationary_distribution(\n",
    "        stochastic_matrix, start_node\n",
    "    )\n",
    "    stationary_distributions.append(stationary_distribution)\n",
    "    print(f\"Finished computing stationary distribution for starting node {start_node}\")\n",
    "    print(f\"Sum of stationary distribution: {stationary_distribution.sum():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_distributions_heatmap(*stationary_distributions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown by the heatmap above, the Random Walks Without Restart do not preserve the local information of the starting node, effectively annihilating the usefulness of RW without restart for node embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Walk With Restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : verify random walk with restart implementation is correct\n",
    "def random_walk_with_restart_to_stationary_distribution(\n",
    "    stochastic_matrix,\n",
    "    start_node,\n",
    "    query_node,\n",
    "    continue_prob,\n",
    "    threshold=1e-10,\n",
    "    max_iterations=1000,\n",
    "    ignore_threshold=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Perform a Random Walk with Restart on a graph represented by a stochastic matrix, starting from a given node,\n",
    "    until the stationary distribution is reached or the maximum number of iterations is exceeded.\n",
    "\n",
    "    :param stochastic_matrix: The stochastic matrix representing the graph.\n",
    "    :param start_node: The index of the starting node.\n",
    "    :param restart_prob: The probability of restarting to the initial node.\n",
    "    :param threshold: The threshold for the difference between successive distribution vectors.\n",
    "    :param max_iterations: The maximum number of iterations to perform.\n",
    "    :param ignore_threshold: Whether to ignore the threshold and always perform the maximum number of iterations.\n",
    "    :return: The stationary distribution vector of the random walk.\n",
    "    \"\"\"\n",
    "    num_nodes = stochastic_matrix.shape[0]\n",
    "\n",
    "    # Initialize the distribution vector q_k and the restart vector v\n",
    "    q_k = np.zeros(num_nodes)\n",
    "    q_k[start_node] = 1\n",
    "    v = np.zeros(num_nodes)\n",
    "    v[query_node] = 1\n",
    "\n",
    "    i = 0\n",
    "    while True:\n",
    "        if i >= max_iterations:\n",
    "            print(\"Maximum number of iterations exceededed.\")\n",
    "            break\n",
    "\n",
    "        q_k_next = (\n",
    "            continue_prob * np.dot(q_k, stochastic_matrix) + (1 - continue_prob) * v\n",
    "        )\n",
    "\n",
    "        if np.linalg.norm(q_k_next - q_k) < threshold and not ignore_threshold:\n",
    "            break\n",
    "\n",
    "        q_k = q_k_next\n",
    "        i += 1\n",
    "\n",
    "    print(f\"Number of iterations: {i}\")\n",
    "\n",
    "    return q_k_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_distributions_heatmap(\n",
    "    *distributions, node_labels=None, distribution_labels=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualize multiple stationary distributions as a stacked heatmap.\n",
    "\n",
    "    :param distributions: Stationary distributions obtained from random walks.\n",
    "    :param node_labels: Labels for the nodes (optional).\n",
    "    :param distribution_labels: Labels for the distributions (optional).\n",
    "    \"\"\"\n",
    "    data = np.vstack(distributions)\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    ax = sns.heatmap(\n",
    "        data,\n",
    "        annot=False,\n",
    "        cmap=\"viridis\",\n",
    "        yticklabels=distribution_labels\n",
    "        if distribution_labels\n",
    "        else [f\"Dist {i + 1}\" for i in range(len(distributions))],\n",
    "        xticklabels=node_labels if node_labels else [],\n",
    "    )\n",
    "    ax.set_title(\"Comparison of Stationary Distributions from Random Walks\")\n",
    "    ax.set_xlabel(\"Nodes\")\n",
    "    ax.set_ylabel(\"Distributions\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_top_n_nodes_line_plots(distributions, top_n=10, labels=None):\n",
    "    \"\"\"\n",
    "    Visualize the top N nodes from each distribution using line plots.\n",
    "\n",
    "    :param distributions: A list of distributions (numpy arrays).\n",
    "    :param top_n: The number of top nodes to consider.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    for i, distribution in enumerate(distributions):\n",
    "        # Sort the distribution and pick the top N nodes\n",
    "        top_nodes_indices = np.argsort(distribution)[-top_n:]\n",
    "        top_nodes_values = distribution[top_nodes_indices]\n",
    "\n",
    "        # Plotting\n",
    "        plt.plot(\n",
    "            top_nodes_indices,\n",
    "            top_nodes_values,\n",
    "            marker=\"o\",\n",
    "            label=f\"Distribution {i+1}\" if labels is None else labels[i],\n",
    "        )\n",
    "\n",
    "    plt.title(f\"Top {top_n} Nodes in Each Distribution\")\n",
    "    plt.xlabel(\"Node Index\")\n",
    "    plt.ylabel(\"Probability\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_difference_heatmaps(distributions):\n",
    "    \"\"\"\n",
    "    Visualize the differences between distributions as a heatmap.\n",
    "\n",
    "    :param distributions: A list of distributions (numpy arrays).\n",
    "    \"\"\"\n",
    "    num_distributions = len(distributions)\n",
    "    diff_matrix = np.zeros(\n",
    "        (num_distributions, num_distributions, distributions[0].size)\n",
    "    )\n",
    "\n",
    "    # Compute the differences between each pair of distributions\n",
    "    for i in range(num_distributions):\n",
    "        for j in range(num_distributions):\n",
    "            diff_matrix[i, j] = np.abs(distributions[i] - distributions[j])\n",
    "\n",
    "    # Plotting the difference matrix as a heatmap\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    for i in range(num_distributions):\n",
    "        for j in range(num_distributions):\n",
    "            plt.subplot(\n",
    "                num_distributions, num_distributions, i * num_distributions + j + 1\n",
    "            )\n",
    "            sns.heatmap(\n",
    "                np.reshape(diff_matrix[i, j], (1, -1)),\n",
    "                annot=False,\n",
    "                cmap=\"viridis\",\n",
    "                cbar=False,\n",
    "            )\n",
    "            plt.title(f\"Diff between Dist {i+1} and Dist {j+1}\")\n",
    "            plt.yticks([])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_top_n_nodes_box_plots(distributions, top_n=10):\n",
    "    \"\"\"\n",
    "    Visualize the top N nodes from each distribution using box plots.\n",
    "\n",
    "    :param distributions: A list of distributions (numpy arrays).\n",
    "    :param top_n: The number of top nodes to consider.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Prepare data for box plots\n",
    "    top_nodes_data = []\n",
    "    for distribution in distributions:\n",
    "        top_nodes_indices = np.argsort(distribution)[-top_n:]\n",
    "        top_nodes_data.append(distribution[top_nodes_indices])\n",
    "\n",
    "    # Create box plots for the top N nodes\n",
    "    plt.boxplot(top_nodes_data)\n",
    "    plt.title(f\"Top {top_n} Nodes Box Plot Comparison\")\n",
    "    plt.xlabel(\"Distribution\")\n",
    "    plt.ylabel(\"Probability\")\n",
    "    plt.xticks(\n",
    "        range(1, len(distributions) + 1),\n",
    "        [f\"Dist {i+1}\" for i in range(len(distributions))],\n",
    "    )\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_top_n_node_ranking_scatter_plots(distributions, top_n=10, labels=None):\n",
    "    \"\"\"\n",
    "    Visualize the top N node rankings in each distribution using scatter plots.\n",
    "\n",
    "    :param distributions: A list of distributions (numpy arrays).\n",
    "    :param top_n: The number of top nodes to consider.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    for i, distribution in enumerate(distributions):\n",
    "        # Sort the distribution and pick the top N nodes\n",
    "        top_nodes_indices = np.argsort(distribution)[-top_n:]\n",
    "        top_nodes_values = distribution[top_nodes_indices]\n",
    "\n",
    "        # Plotting the top N nodes\n",
    "        plt.scatter(\n",
    "            top_nodes_indices, top_nodes_values, label=f\"Distribution {i+1}\" if labels is None else labels[i], alpha=0.7\n",
    "        )\n",
    "\n",
    "    plt.title(f\"Top {top_n} Node Rankings in Each Distribution\")\n",
    "    plt.xlabel(\"Node Index\")\n",
    "    plt.ylabel(\"Probability\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_distributions_with_pca(distributions):\n",
    "    \"\"\"\n",
    "    Apply PCA to reduce the dimensionality of the distributions to 2D for visualization.\n",
    "\n",
    "    :param distributions: A list of distributions (numpy arrays).\n",
    "    \"\"\"\n",
    "    # Combine the distributions for PCA\n",
    "    combined_distributions = np.stack(distributions)\n",
    "\n",
    "    # Apply PCA to reduce to two dimensions\n",
    "    pca = PCA(n_components=2)\n",
    "    reduced_distributions = pca.fit_transform(combined_distributions)\n",
    "\n",
    "    # Plot the reduced distributions\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for i, reduced_distribution in enumerate(reduced_distributions):\n",
    "        plt.scatter(\n",
    "            reduced_distribution[0],\n",
    "            reduced_distribution[1],\n",
    "            label=f\"Distribution {i+1}\",\n",
    "            marker=\"o\",\n",
    "        )\n",
    "\n",
    "    plt.title(\"PCA Reduced Distributions\")\n",
    "    plt.xlabel(\"PCA Component 1\")\n",
    "    plt.ylabel(\"PCA Component 2\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_1, node_2 = data.loc[0, \"node1\"], data.loc[0, \"node2\"]\n",
    "print(f\"Node 1: {node_1}\")\n",
    "print(f\"Node 2: {node_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find index of node 1 and node 2 in all nodes\n",
    "node_1_idx = np.where(all_nodes_cleaned == node_1)[0][0]\n",
    "node_2_idx = np.where(all_nodes_cleaned == node_2)[0][0]\n",
    "print(f\"Node 1 index: {node_1_idx}\")\n",
    "print(f\"Node 2 index: {node_2_idx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Varying restarting probability, fixed restarting node, fixed random starting node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first experiment we will fix N1 as the restart node, fix a random q0 as the starting node, and vary the probability of restarting from N1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continue_probs = [0.2, 0.5, 0.8]\n",
    "stationary_distributions = []\n",
    "start_node = 1022\n",
    "for prob in continue_probs:\n",
    "    print(f\"Starting node: {start_node}\")\n",
    "    print(f\"Restarting node: {node_2_idx}\")\n",
    "    print(f\"Restart probability: {1 - prob}\")\n",
    "    stationary_distribution = random_walk_with_restart_to_stationary_distribution(\n",
    "        stochastic_matrix, start_node, node_2_idx, prob, ignore_threshold=False\n",
    "    )\n",
    "    stationary_distributions.append(stationary_distribution)\n",
    "    print(f\"Finished computing stationary distribution for starting node {start_node}\")\n",
    "    print(f\"Sum of stationary distribution: {stationary_distribution.sum():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter top 10visualize_node_ranking_scatter_plots\n",
    "visualize_top_n_node_ranking_scatter_plots(stationary_distributions, top_n=10, labels=[f\"1 - p = {1 - prob:.1f}\" for prob in continue_probs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most nodes obtain a uniform distribution, only N1 (restart node) has a higher value of 80% (the probability of restarting there). The other visited nodes are fairly similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chaning the starting node doesn't change the stationary distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's likely that these nodes are in the neighborhood of the restarting node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing $p = 0.2$, starting node, but varying restarting node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
