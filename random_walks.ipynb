{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Walks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"9606.hn_HS_CX.edge\", sep=\"\\t\", header=None)\n",
    "data.drop([3, 4, 5], axis=1, inplace=True)\n",
    "data.columns = [\"node1\", \"node2\", \"weight\"]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nodes = np.array(\n",
    "    list(set(data[\"node1\"].unique()).union(set(data[\"node2\"].unique())))\n",
    ")\n",
    "print(\"Total number of nodes: {}\".format(len(all_nodes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Adjacency Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_symmetric_adjacency_matrix(df):\n",
    "    \"\"\"\n",
    "    Create a symmetric adjacency matrix from a dataframe containing edges and weights.\n",
    "    \"\"\"\n",
    "    df_symmetric = pd.concat(\n",
    "        [df, df.rename(columns={\"node1\": \"node2\", \"node2\": \"node1\"})]\n",
    "    )\n",
    "    df_symmetric = df_symmetric.groupby([\"node1\", \"node2\"]).weight.mean().reset_index()\n",
    "\n",
    "    adjacency_matrix = df_symmetric.pivot(\n",
    "        index=\"node1\", columns=\"node2\", values=\"weight\"\n",
    "    ).fillna(0)\n",
    "\n",
    "    matrix_np = adjacency_matrix.to_numpy()\n",
    "    symmetrized_matrix_np = matrix_np + matrix_np.T - np.diag(matrix_np.diagonal())\n",
    "\n",
    "    return symmetrized_matrix_np\n",
    "\n",
    "\n",
    "def remove_self_loops_and_small_components(adj_matrix, threshold_components=4):\n",
    "    \"\"\"\n",
    "    Remove self-loops and small disconnected components from the graph represented by the adjacency matrix.\n",
    "    Also, keep track of the removed nodes.\n",
    "    \"\"\"\n",
    "    G = nx.from_numpy_array(adj_matrix)\n",
    "    removed_nodes = []\n",
    "\n",
    "    for edge in nx.selfloop_edges(G):\n",
    "        G.remove_edge(*edge)\n",
    "\n",
    "    components = list(nx.connected_components(G))\n",
    "    for component in components:\n",
    "        if len(component) < threshold_components:\n",
    "            removed_nodes.extend(component)\n",
    "            for node in component:\n",
    "                G.remove_node(node)\n",
    "\n",
    "    cleaned_adj_matrix = nx.to_numpy_array(G)\n",
    "\n",
    "    return cleaned_adj_matrix, set(removed_nodes)\n",
    "\n",
    "\n",
    "def normalize_to_stochastic_matrix(adj_matrix):\n",
    "    \"\"\"\n",
    "    Normalize an adjacency matrix so that each row sums to 1, creating a stochastic matrix.\n",
    "    \"\"\"\n",
    "    matrix_np = np.array(adj_matrix)\n",
    "\n",
    "    row_sums = matrix_np.sum(axis=1, keepdims=True)\n",
    "\n",
    "    row_sums[row_sums == 0] = 1\n",
    "\n",
    "    stochastic_matrix = matrix_np / row_sums\n",
    "\n",
    "    return stochastic_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_mat = create_symmetric_adjacency_matrix(data)\n",
    "cleaned_adj_mat, removed_nodes = remove_self_loops_and_small_components(adj_mat)\n",
    "\n",
    "removed_nodes = list(removed_nodes)\n",
    "all_nodes_cleaned = np.delete(all_nodes, removed_nodes)\n",
    "avg_degree = np.count_nonzero(cleaned_adj_mat, axis=1).mean()\n",
    "\n",
    "print(f\"Number of removed nodes: {len(removed_nodes)}\")\n",
    "print(f\"Number of nodes after cleaning: {len(all_nodes_cleaned)}\")\n",
    "print(f\"Average degree: {avg_degree:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stochastic_matrix = normalize_to_stochastic_matrix(cleaned_adj_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Walk Without Restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_walk_without_restart_to_stationary_distribution(\n",
    "    stochastic_matrix, start_node, threshold=1e-4, max_iterations=1000\n",
    "):\n",
    "    \"\"\"\n",
    "    Perform a random walk on a graph represented by a stochastic matrix, starting from a given node,\n",
    "    until the stationary distribution is reached or the maximum number of iterations is exceeded.\n",
    "\n",
    "    :param stochastic_matrix: The stochastic matrix representing the graph.\n",
    "    :param start_node: The index of the starting node.\n",
    "    :param threshold: The threshold for the difference between successive distribution vectors.\n",
    "    :param max_iterations: The maximum number of iterations to perform.\n",
    "    :return: The stationary distribution vector of the random walk.\n",
    "    \"\"\"\n",
    "    num_nodes = stochastic_matrix.shape[0]\n",
    "\n",
    "    q_k = np.zeros(num_nodes)\n",
    "    q_k[start_node] = 1\n",
    "\n",
    "    for _ in range(max_iterations):\n",
    "        q_k_next = np.dot(q_k, stochastic_matrix)\n",
    "\n",
    "        if np.linalg.norm(q_k_next - q_k) < threshold:\n",
    "            break\n",
    "\n",
    "        q_k = q_k_next\n",
    "\n",
    "    return q_k_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationary_distributions = []\n",
    "for i in range(3):\n",
    "    start_node = np.random.randint(stochastic_matrix.shape[0])\n",
    "    print(f\"Starting node: {start_node}\")\n",
    "    stationary_distribution = random_walk_without_restart_to_stationary_distribution(\n",
    "        stochastic_matrix, start_node\n",
    "    )\n",
    "    stationary_distributions.append(stationary_distribution)\n",
    "    print(f\"Finished computing stationary distribution for starting node {start_node}\")\n",
    "    print(f\"Sum of stationary distribution: {stationary_distribution.sum():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_distributions_heatmap(*stationary_distributions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown by the heatmap above, the Random Walks Without Restart do not preserve the local information of the starting node, effectively annihilating the usefulness of RW without restart for node embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Walk With Restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_walk_with_restart_to_stationary_distribution(\n",
    "    stochastic_matrix,\n",
    "    start_node,\n",
    "    query_node,\n",
    "    continue_prob,\n",
    "    threshold=1e-10,\n",
    "    max_iterations=1000,\n",
    "    ignore_threshold=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Perform a Random Walk with Restart on a graph represented by a stochastic matrix, starting from a given node,\n",
    "    until the stationary distribution is reached or the maximum number of iterations is exceeded.\n",
    "\n",
    "    :param stochastic_matrix: The stochastic matrix representing the graph.\n",
    "    :param start_node: The index of the starting node.\n",
    "    :param restart_prob: The probability of restarting to the initial node.\n",
    "    :param threshold: The threshold for the difference between successive distribution vectors.\n",
    "    :param max_iterations: The maximum number of iterations to perform.\n",
    "    :param ignore_threshold: Whether to ignore the threshold and always perform the maximum number of iterations.\n",
    "    :return: The stationary distribution vector of the random walk.\n",
    "    \"\"\"\n",
    "    num_nodes = stochastic_matrix.shape[0]\n",
    "\n",
    "    # Initialize the distribution vector q_k and the restart vector v\n",
    "    q_k = np.zeros(num_nodes)\n",
    "    q_k[start_node] = 1\n",
    "    v = np.zeros(num_nodes)\n",
    "    v[query_node] = 1\n",
    "\n",
    "    i = 0\n",
    "    while True:\n",
    "        if i >= max_iterations:\n",
    "            print(\"Maximum number of iterations exceededed.\")\n",
    "            break\n",
    "\n",
    "        q_k_next = (\n",
    "            continue_prob * np.dot(q_k, stochastic_matrix) + (1 - continue_prob) * v\n",
    "        )\n",
    "\n",
    "        if np.linalg.norm(q_k_next - q_k) < threshold and not ignore_threshold:\n",
    "            break\n",
    "\n",
    "        q_k = q_k_next\n",
    "        i += 1\n",
    "    \n",
    "    print(f\"Number of iterations: {i}\")\n",
    "\n",
    "    return q_k_next\n",
    "\n",
    "\n",
    "def visualize_distributions_heatmap(\n",
    "    *distributions, node_labels=None, distribution_labels=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualize multiple stationary distributions as a heatmap.\n",
    "\n",
    "    :param distributions: Stationary distributions obtained from random walks.\n",
    "    :param node_labels: Labels for the nodes (optional).\n",
    "    :param distribution_labels: Labels for the distributions (optional).\n",
    "    \"\"\"\n",
    "    data = np.vstack(distributions)\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    ax = sns.heatmap(\n",
    "        data,\n",
    "        annot=False,\n",
    "        cmap=\"viridis\",\n",
    "        yticklabels=distribution_labels\n",
    "        if distribution_labels\n",
    "        else [f\"Dist {i + 1}\" for i in range(len(distributions))],\n",
    "        xticklabels=node_labels if node_labels else [],\n",
    "    )\n",
    "    ax.set_title(\"Comparison of Stationary Distributions from Random Walks\")\n",
    "    ax.set_xlabel(\"Nodes\")\n",
    "    ax.set_ylabel(\"Distributions\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_1, node_2 = data.loc[0, \"node1\"], data.loc[0, \"node2\"]\n",
    "print(f\"Node 1: {node_1}\")\n",
    "print(f\"Node 2: {node_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find index of node 1 and node 2 in all nodes\n",
    "node_1_idx = np.where(all_nodes_cleaned == node_1)[0][0]\n",
    "node_2_idx = np.where(all_nodes_cleaned == node_2)[0][0]\n",
    "print(f\"Node 1 index: {node_1_idx}\")\n",
    "print(f\"Node 2 index: {node_2_idx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Varying restarting probability, fixed restarting node, fixed random starting node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first experiment we will fix N1 as the restart node, fix a random q0 as the starting node, and vary the probability of restarting from N1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continue_probs = [0.2, 0.5, 0.8]\n",
    "stationary_distributions = []\n",
    "start_node = 2732\n",
    "for prob in continue_probs:\n",
    "    print(f\"Starting node: {start_node}\")\n",
    "    print(f\"Restart probability: {1 - prob}\")\n",
    "    stationary_distribution = random_walk_with_restart_to_stationary_distribution(\n",
    "        stochastic_matrix, start_node, node_1_idx, prob, ignore_threshold=False\n",
    "    )\n",
    "    stationary_distributions.append(stationary_distribution)\n",
    "    print(f\"Finished computing stationary distribution for starting node {start_node}\")\n",
    "    print(f\"Sum of stationary distribution: {stationary_distribution.sum():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_distributions_heatmap(*stationary_distributions, distribution_labels=continue_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationary_distributions[0].mean(), 1 / len(all_nodes_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationary_distributions[0].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationary_distributions[0][9445]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most nodes obtain a uniform distribution, only N1 (restart node) has a higher value of 80% (the probability of restarting there)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO : Examine the probability around its neighborhood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed restarting probability, fixed restarting node, varying random starting node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the second experiment we will by changing the starting node, but fixing the restart node to N1 and the probability of restarting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continue_prob = 0.2\n",
    "stationary_distributions = []\n",
    "for i in range(3):\n",
    "    start_node = np.random.randint(stochastic_matrix.shape[0])\n",
    "    print(f\"Starting node: {start_node}\")\n",
    "    print(f\"Restart probability: {1 - prob}\")\n",
    "    stationary_distribution = random_walk_with_restart_to_stationary_distribution(\n",
    "        stochastic_matrix, start_node, node_1_idx, prob, ignore_threshold=False\n",
    "    )\n",
    "    stationary_distributions.append(stationary_distribution)\n",
    "    print(f\"Finished computing stationary distribution for starting node {start_node}\")\n",
    "    print(f\"Sum of stationary distribution: {stationary_distribution.sum():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_distributions_heatmap(*stationary_distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
